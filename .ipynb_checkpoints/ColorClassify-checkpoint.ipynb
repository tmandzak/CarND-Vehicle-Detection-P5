{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The scikit-learn version is 0.18.1.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import time\n",
    "import sklearn\n",
    "print('The scikit-learn version is {}.'.format(sklearn.__version__))\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split  # if you are using scikit-learn >= 0.18 then use this:\n",
    "#from sklearn.cross_validation import train_test_split  # for scikit-learn version <= 0.17\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Read in car and non-car images\n",
    "cars = glob.glob('../images/vehicles/**/*.png', recursive=True)\n",
    "notcars = glob.glob('../images/non-vehicles/**/*.png', recursive=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in car and non-car images\n",
    "cars = glob.glob('../images/vehicles_smallset/**/*.jpeg', recursive=True)\n",
    "notcars = glob.glob('../images/non-vehicles_smallset/**/*.jpeg', recursive=True)\n",
    "len(cars), len(notcars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, size=(32, 32)):\n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the color channels separately\n",
    "    if len(img.shape)<3:\n",
    "        hist_features = np.histogram(img, bins=nbins, range=bins_range)[0]\n",
    "    else:\n",
    "        hist_features = np.histogram(img[:,:,0], bins=nbins, range=bins_range)[0]\n",
    "        for i in range(1, img.shape[2]):\n",
    "            # Concatenate the histograms into a single feature vector\n",
    "            hist_features = np.concatenate((hist_features, np.histogram(img[:,:,i], bins=nbins, range=bins_range)[0]))\n",
    "        \n",
    "    # Return the feature vector\n",
    "    return hist_features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256)):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'LS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)[:,:,1:]        \n",
    "            elif cspace == 'L':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)[:,:,1] \n",
    "            elif cspace == 'S':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)[:,:,2]    \n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "        else: feature_image = np.copy(image)      \n",
    "        # Apply bin_spatial() to get spatial color features\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        # Apply color_hist() also with a color space option now\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "        # Append the new feature vector to the features list\n",
    "        features.append(np.concatenate((spatial_features, hist_features)))\n",
    "    # Return list of feature vectors\n",
    "    return features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO play with these values to see how your classifier\n",
    "# performs under different binning scenarios\n",
    "spatial = 8\n",
    "histbin = 32\n",
    "\n",
    "cspace = 'LS'\n",
    "\n",
    "car_features = extract_features(cars, cspace=cspace, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=(0, 256))\n",
    "notcar_features = extract_features(notcars, cspace=cspace, spatial_size=(spatial, spatial),\n",
    "                        hist_bins=histbin, hist_range=(0, 256))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 feature(s) (shape=(2, 0)) while a minimum of 1 is required by StandardScaler.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-5-da707bb65b9a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcar_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnotcar_features\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# Fit a per-column scaler\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mX_scaler\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mStandardScaler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# Apply the scaler to X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mscaled_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_scaler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETASMAK\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;31m# Reset internal state before fitting\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpartial_fit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETASMAK\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\preprocessing\\data.py\u001b[0m in \u001b[0;36mpartial_fit\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    581\u001b[0m         X = check_array(X, accept_sparse=('csr', 'csc'), copy=self.copy,\n\u001b[0;32m    582\u001b[0m                         \u001b[0mensure_2d\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 583\u001b[1;33m                         estimator=self, dtype=FLOAT_DTYPES)\n\u001b[0m\u001b[0;32m    584\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    585\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\Users\\ETASMAK\\AppData\\Local\\Continuum\\Miniconda3\\envs\\carnd-term1\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    422\u001b[0m                              \u001b[1;34m\" a minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    423\u001b[0m                              % (n_features, shape_repr, ensure_min_features,\n\u001b[1;32m--> 424\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    425\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    426\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mwarn_on_dtype\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mdtype_orig\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mdtype_orig\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 feature(s) (shape=(2, 0)) while a minimum of 1 is required by StandardScaler."
     ]
    }
   ],
   "source": [
    "# Create an array stack of feature vectors\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'poly', 'rbf', 'sigmoid'), 'C':[0.1, 1, 10]}\n",
    "svr = SVC()\n",
    "clf = GridSearchCV(svr, parameters)\n",
    "clf.fit(scaled_X, y)\n",
    "clf.best_params_   # {'C': 10, 'kernel': 'rbf'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split up data into randomized training and test sets\n",
    "rand_state = 0 #np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(scaled_X, y, test_size=0.2, random_state=rand_state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Using spatial binning of:',spatial,\n",
    "    'and', histbin,'histogram bins')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "#svc = LinearSVC()\n",
    "\n",
    "svc = SVC(C = 10, kernel='rbf', gamma='auto')\n",
    "\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()\n",
    "n_predict = 10\n",
    "print('My SVC predicts: ', svc.predict(X_test[0:n_predict]))\n",
    "print('For these',n_predict, 'labels: ', y_test[0:n_predict])\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 5), 'Seconds to predict', n_predict,'labels with SVC')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "HLS\n",
    "Using spatial binning of: 0 and 32 histogram bins\n",
    "Feature vector length: 96\n",
    "0.05 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9978\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.0 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 0 and 32 histogram bins\n",
    "Feature vector length: 96\n",
    "0.07 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9914\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.0 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 1 and 32 histogram bins\n",
    "Feature vector length: 99\n",
    "0.06 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9892\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.01563 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 2 and 32 histogram bins\n",
    "Feature vector length: 108\n",
    "0.07 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9935\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.0 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 4 and 32 histogram bins\n",
    "Feature vector length: 144\n",
    "0.15 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9914\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.003 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 8 and 32 histogram bins\n",
    "Feature vector length: 288\n",
    "0.5 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9871\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.00104 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 16 and 16 histogram bins\n",
    "Feature vector length: 816\n",
    "1.18 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9785\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.0 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 16 and 32 histogram bins\n",
    "Feature vector length: 864\n",
    "1.27 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9871\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.01562 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 32 and 32 histogram bins\n",
    "Feature vector length: 3168\n",
    "4.35 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9871\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.03126 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 64 and 32 histogram bins\n",
    "Feature vector length: 12384\n",
    "16.48 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9656\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  1.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.07813 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 32 and 64 histogram bins\n",
    "Feature vector length: 3264\n",
    "4.78 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9871\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.03124 Seconds to predict 10 labels with SVC"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Using spatial binning of: 32 and 128 histogram bins\n",
    "Feature vector length: 3456\n",
    "4.79 Seconds to train SVC...\n",
    "Test Accuracy of SVC =  0.9871\n",
    "My SVC predicts:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "For these 10 labels:  [ 0.  1.  1.  0.  1.  0.  1.  1.  0.  0.]\n",
    "0.03125 Seconds to predict 10 labels with SVC"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
